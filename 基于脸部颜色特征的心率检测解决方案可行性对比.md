## 基于RGB或红外摄像头的乘客心率检测解决方案对比

目前针对心率和呼吸频率的检测方案主要包括三种，底层原理都是**远程光电容积脉搏波 (rPPG)**，主要区别在于脉冲信号组合方式的不同。

|         方案编号         |        方案简介         |     功能      |
| :----------------------: | :---------------------: | :-----------: |
| **解决方案1：开源+修改** | rPPG 远程光电容积脉搏波 |     心率      |
| **解决方案2：开源+修改** | rPPG 远程光电容积脉搏波 | 心率+呼吸频率 |
|   **解决方案3：自研**    | rPPG 远程光电容积脉搏波 | 心率+呼吸频率 |
|   **解决方案4：开源**    | rPPG 远程光电容积脉搏波 |     心率      |

远程光电容积脉搏波 (rPPG) 通过使用多波长 RGB 相机或红外相机检测**人体皮肤表面脉冲引起的细微颜色变化**，实现对人体心脏活动的非接触式监测。

### 解决方案1：多线程运算远程PPG（rPPG）算法（开源+修改）

这里分为两大类，共四种方法用于从视频流中提取脉冲信号：

```shell
# Channel_based：使用特定通道数据（GREEN）或通道间的简单线性组合（G-R）实现。 
# Model_based：CHROM模型通过假设标准化的肤色对图像进行白平衡来线性组合色度信号，PBV使用不同波长下血容量变化的特征来明确区分脉冲引起的颜色变化和 RGB 测量中的运动噪声（基于光组织相互作用模型来确定投影矢量）
```

#### 1、皮肤反射模型

考虑一个光源照射一块含有脉动血液的人体皮肤组织和一个记录这幅图像的远程彩色相机。我们进一步假设光源具有恒定的光谱成分，但强度是变化的（在相机处观察到的强度取决于光源到皮肤组织和相机传感器的距离）。相机测量的皮肤有一种特定的颜色（相机测量的肤色是光源（例如强度和光谱）、固有肤色和相机颜色通道灵敏度的组合），这种颜色会随着时间的推移而变化，这是由于运动引起的强度/镜面反射的变化和脉冲引起的细微的颜色变化。这些时间变化与亮度强度水平成正比。

参考论文1：[基于移动端的非接触心率检测系统研究与设计](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/http://www.jsjclykz.com/jsjclykz/article/pdf/202212031337?file_name=8101D5DAB1C08948B0992B13035C0C5BF6DE9DF210B7B101834D1DF784CE6CFA5A90B1771EDABA9FE12B03C69BE94E5EF1F642FF487F804EDE23DC90F70742C35F073423EEFFDC5E&open_type=self)

参考论文2：[Ivrr-PPG: An Illumination Variation Robust Remote-PPG Algorithm for Monitoring Heart Rate of Drivers](https://ieeexplore.ieee.org/abstract/document/10113355)

![心率检测](C:\Users\kq198\Desktop\assets\心率检测.png)

基于二色反射模型，记录的图像序列中每个皮肤像素的反射可以定义为 RGB 通道中的时变函数：
$$
C_kt=I_t×(V_s(t)+V_d(t)+V_n(t))
$$
式中：$C_t(t)$表示第$k$个皮肤像素在$t$时刻的像素值，$I(t)$表示光照强度，由光源本身亮度变化以及光源、皮肤组织和相机之间的距离决定，并受$V_s(t)$和$V_d(t)$两种反射的调制。$V_s(t)$表示镜面反射，代表由皮肤发烧发出类似镜面的反射光；$V_d(t)$表示漫反射，代表由皮肤组织散射和吸收的光；$V_n(t)$表示相机的量化噪声。

镜面反射$V_s(t)$来自皮肤表面，类似于镜面的光照反射。由于大部分光线均被皮肤表面反射，只有少部分光线进入皮肤组织，因此镜面反射是两种反射成分的主要部分，且不包含任何脉搏信息。但由于人体运动会导致光线、皮肤表面和相机的角度和距离发生变化，所以镜面反射也包含变化的成分。由此，$V_s(t)$定义为：
$$
V_s(t)=u_s(s_0+s_t)
$$
式中，$u_s$表示由相机捕捉的镜面反射光光谱的单位颜色向量，即红、绿、蓝三种颜色对镜面反射光强的贡献程度；$s_0$和$s_t$分别代表镜面反射的直流部分和交流部分的光照强度。

漫反射$V_d(t)$与被皮肤组织吸收的反射光线有关，是脉搏信号的主要成分。皮肤组织对光照反射的影响主要与皮肤表皮组织的色素沉着，如黑色素、胡萝卜素，以及血液中的血红蛋白浓度有关。其中黑色素、胡萝卜素等影响皮肤的固有反射，随时间保持不变；而血红蛋白浓度随心脏活动而发生周期性变化。因此，经血红蛋白反射的光线强度也产生周期性变化，从而反应脉搏信息。则漫反射$V_d(t)$可以定义为：
$$
V_d(t)=u_d∙d_0+u_p∙p(t)
$$
式中，$u_d$表示皮肤组织的单位颜色向量，其方向主要由色素沉着决定，和肤色的深浅有关；$d_0$表示固有的漫反射强度。由于血液对不同颜色光线的吸收程度不同，因此$u_p$代表脉搏信号中不同颜色通道的贡献程度，$p(t)$表示脉搏信号强度。

镜面反射$V_s(t)$和漫反射$V_d(t)$中都包含不随时间改变的静止部分和随时间改变的动态部分，将两种反射的静态部分组合起来，可表示为：
$$
u_c ∙ c_0 = u_s ∙ s_0 + u_d ∙ d_0
$$
式中，$u_c$表示皮肤固有反射的单位颜色向量；$c_0$表示固有反射的光强度。

同样地，$I_t$也可以分为固有光强$I_0$和随时间变化的光强$i(t)$，两者具有相同的方向，可以表示为：
$$
I_t=I_0∙(1+i(t))
$$
带入原模型，可以得到皮肤反射模型为：
$$
C_k(t)=I_0∙(1+i(t))(u_s∙s_t+u_c∙c_0+u_p∙p(t)+V_n(t))
$$
式中，$I_0∙u_c∙c_0$代表信号的大而稳定的直流分量，其大小不随时间变化。现有rPPG方法大多是通过对每一帧ROI区域中的像素点进行空间平均来构成时域信号，而足够像素点的空间平均能够有效降低相机的量化噪声，即可忽略$V_n(t)$。同时，相比于相机捕捉的直流分量，交流分量的强度很小，因此交流分量的乘积项可以忽略不计，最终可得：
$$
C_kt≈I_0∙u_c∙c_0+I_0∙u_c∙c_0+I_0∙u_c∙s_t+I_0∙u_p∙p(t)
$$
至此，观测值$C(t)$变成三个源信号$i(t)$、$s(t)$、$p(t)$的线性混合。即表示通过线性投影可以分离这些源信号。则从观察道德RGB信号中提取脉冲信号的任务可以转化为定义投影平面以分解$C(t)$，最终得到脉搏信号$p(t)$。

#### 2、方案实施过程

<img src="C:\Users\kq198\Desktop\assets\方案实施过程.png" alt="方案实施过程" style="zoom: 25%;" />

> [!NOTE]
>
> 1. 使用电脑摄像头采集画面；
> 2. 使用shape_predictor_81_face_landmarks模型获得人脸的81个特征点；
> 3. 连接特征点闭合成多边形，采集人脸左右侧脸颊和额头的mask，保证采集到的mask不包含外界环境信息，获取感兴趣的区域ROI；
> 4. 计算各ROI的颜色直方图，提取RGB通道；
> 5. 将各ROI的RGB数据压入循环队列；
> 6. 根据QComboBox中所选择的信号提取手段，处理ROI的RGB队列并获取bvp信号；
> 7. 使用Obspy包下到detrend工具滤除bvp信号的多项式趋势，后使用5阶Butterworth带通滤波器滤波；
> 8. 参考CHROM和POS方法，对滤波信号FFT后计算其频谱，随后峰值检波获取各ROI的瞬时心率；
> 9. 加权更新心率$BPM_n=α⋅BPM_{n-1}+(1-α)⋅BPM_{Sig(n)}$，取$α=0.95$保证各ROI的心率结果不会跳变；
> 10. 基于各ROI的原始bvp信号峰峰值与频谱泄露程度设置各ROI的BPM置信度，基于置信度加权求和计算最终心率结果。

实际情况由于数据处理计算量较大，单线程运行极易导致画面采集卡顿，因此采用多进程手段将以上步骤划分为多个线程，使用队列与共享内存实现线程见通信。线程调度为：

![线程调度](C:\Users\kq198\Desktop\assets\线程调度.png)

#### 3、静态效果

经过静态检测实验和实车动态检测实验，在阈值极限为30FPS和60FPS情况下，**静态实验下**主要界面结果包括：

##### 1）PC RGB Camera（30FPS）

![image-20240827170330927](C:\Users\kq198\Desktop\assets\PCRGB30FPS静态实验结果)

##### 2）PC RGB Camera（60FPS）

![image-20240827170200663](C:\Users\kq198\Desktop\assets\PCRGB60FPS静态结果)

##### 3）External RGB Camera（30FPS）

![image-20240827170951912](C:\Users\kq198\Desktop\assets\外接RGB30FPS静态结果)

##### 4）External Infrared Camera（30FPS）

![image-20240827165953178](C:\Users\kq198\Desktop\assets\红外摄像头30FPS静态结果)

##### 5）静态结果分析

> [!IMPORTANT]
>
> 1. 因为GREEN采集到的是原始信号，对于头动极为敏感，微小运动即可导致难以detrend的低频扰动，对于大部分运动情况下GREEN方案效果极不理想；
> 2. G-R因为通道相减，滤除了部分共模干扰，抗头动干扰能力更强，但信号相较于GREEN更不明显，含有更多噪声毛刺；
> 3. CHROM和PBV同为Model-based方案，但PBV效果较差，可能是由于静态测试条件下与开源模型形成的采集环境和光照环境不吻合导致的，且PBV对于头动与GREEN方法一样敏感；
> 4. CHROM算法对于环境与镜头具有更高的鲁棒性。
> 5. **红外摄像机可以去除算法对于光线条件变化的影响**，在光线条件发生改变时也可正常进行心率计算。

> [!WARNING]
>
> 该算法通过捕捉额头、左脸颊、右脸颊的的多数脸部特征点，在**三部分区域同时能够捕捉**的条件下开始计算，并在一段时间内心率计算趋于稳定。因此，若测试情况下的头部发生较大程度的上下或左右转动，即会产生**特征丢生**的现象，会自动停止计算。
>
> <img src="C:\Users\kq198\Desktop\assets\检测停止特征消失" style="zoom: 67%;" />

#### 4、动态效果

结果展示为截图形式，详情查看实车动态算法测试视频。

##### 1）PC RGB Camera（30FPS）

![image-20240828143638163](C:\Users\kq198\Desktop\assets\PCRGB30FPS实车)

##### 2）PC RGB Camera（60FPS）

![image-20240827172839875](C:\Users\kq198\Desktop\assets\PCRGB60FPS动态结果)

##### 3）External RGB Camera（30FPS）

![image-20240827172920123](C:\Users\kq198\Desktop\assets\外接RGB30FPS动态结果)

##### 4）External Infrared Camera（30FPS）

![image-20240828143148235](C:\Users\kq198\Desktop\assets\算法1红外实车测试)

##### 5）动态结果分析

> [!IMPORTANT]
>
> 相比较外接的RGB摄像头，由于PC计算能力以及不同摄像头的帧率阈值不同，在动态检测过程中，PC自带摄像头（视频最高帧率60FPS）在检测过程中帧率能够在15-20FPS，而外接RGB摄像头（视频最高帧率30FPS）在检测过程中帧率最高只能在10FPS左右，导致动态检测的卡顿情况。
>
> 基于红外摄像头的动态测试结果在稳定性和准确性方面，相比RGB摄像头存在较大优势。在车辆转弯、停止、起步等动作情况下，算法能否保持继续运算，同时能够保持对于人脸特征的良好捕捉。同时，在车内光线环境发生变化时不会对计算造成影响，鲁棒性相对更高。

> [!WARNING]
>
> 1. 在动态检测过程中存在**抖动、光线变化、测试人员手部遮挡、计算力不足**的问题，会导致**丢帧或脸部特征丢失**、**计算停止**或**重新计算**的问题；
> 2. 算法**对光线的敏感程度很高**，基本在每次发生光线明暗变化的情况，即使不存在脸部遮挡，也会丢失脸部特征，导致重新计算。
> 3. 由此引申，若测试人员脸部存在**较浓妆造、戴口罩、看书等其他因素遮挡脸部**等情况，无法进行基于脸部颜色特征的心率计算。
> 4. 红外摄像机可以避免光照条件变化对于算法的影响，在光照条件发生改变时仍可继续进行心率计算。
> 5. 静态测试过程中存在的问题，同样存在于实车动态测试的过程中。因此**动态实验结果为多影响因素共同作用的情况。**

---------------------------------

### 解决方案2：基于高斯金字塔的图像颜色空间信号放大（开源+修改）

#### 1、皮肤反射模型

同解决方案1

#### 2、方案实施过程

根据皮肤反射模型，非接触式RPPG心率检测方法将心率信号从原始数据中提取出来。相关信号的特点是具有周期性且与心跳周期频率一致，但由于该信号十分微弱并且容易受到外接环境干扰，则通过基于高斯金字塔的空间滤波方法进行分析以提取更加有用的心率信息。

通过简历拉普拉斯金字塔或高斯金字塔，获取图像数据中的不同空间频率的基带。高斯金字塔是常见的对图像颜色空间进行信号放大的方式，建立高斯金字塔的方式一般为从底层开始对图像进行一层一层向上的迭代计算。处理过程包括：

1. 使用低通滤波器对图像进行平滑处理；
2. 对平滑图像进行下采样，获得一系列尺寸图像；
3. 完成滤波获得指定频率范围内的心率信号；
4. 对提取出来的信号进行放大，提升心率信号的信噪比。

#### 3、静态效果

##### 1）PC RGB Camera（30FPS）

![image-20240828095003651](C:\Users\kq198\Desktop\assets\PCRGB30FPS静态实验结果2)

##### 2）External RGB Camera（30FPS）

![image-20240828095429018](C:\Users\kq198\Desktop\assets\image-20240828095429018.png)

##### 3）External Infrared Camera（30FPS）

![image-20240828100212814](C:\Users\kq198\Desktop\assets\image-20240828100212814.png)

##### 4）静态结果分析

> [!IMPORTANT]
>
> 高斯金字塔对脸部区域进行了颜色增强，在一定程度上**增加了对脸部关键点微弱颜色特征变化的捕捉精确度**，且心率检测情况能够在检测持续一段时间之后趋于稳定，与使用手环检测结果相比相差并不大，同时头部的细微运动并不会影响检测的进行。
>
> 由于外置的RGB和红外摄像头分辨率并不相同，所以基于外置摄像头进行检测时程序内的人脸检测框**没能自适应检测脸部位置**。在此情况下，**相机帧率和相机计算能力对于算法的限制程度得到削弱**，但对于呼吸频率和血氧度的检测**精确度较低，延迟较大**，脸部动作可能会在检测框中停留几十帧，因此检测结果存在**很大的延迟。**

> [!WARNING]
>
> 1. 由于该算法没有设置脸部追踪程序，因此在人脸检测框内，可能不是人脸，也会产生对应的心率、呼吸频率和血氧浓度的检测结果，造成了极大的不稳定性。虽然在某种程度上鲁棒性较好，但是脸部跟踪的确实导致检测结果可信度较低；
> 2. 延迟较高，画面帧数的停留有可能是由于PC计算能力的不足导致的，同时也受算法精确度和线程分配的影响；
> 3. 对于外置摄像头不具备自适应想，需手动调整检测框参数以适应脸部位置。

#### 4、动态效果

##### 1）PC RGB Camera（30FPS）（这里只展示心率计算结果）

<img src="C:\Users\kq198\Desktop\assets\image-20240828144153035.png" alt="image-20240828144153035" style="zoom: 67%;" />

##### 2）External RGB Camera（30FPS）

![image-20240828144332116](C:\Users\kq198\Desktop\assets\外接RGB算法2实车测试)

##### 3）External Infrared Camera（30FPS）

![image-20240828144537489](C:\Users\kq198\Desktop\assets\算法2外接红外实车测试)

##### 4）动态结果分析

> [!IMPORTANT]
>
> 算法本身计算的鲁棒性较强，在车辆正常行驶过程中的转弯、刹车、起步等动作所导致的摄像头不稳定因素影响下，测试人员头部存在较大程度运动仍可进行计算，一定程度上减少了对于脸部特征高覆盖程度的需求。

> [!WARNING]
>
> 1. 计算延迟高。虽然心率和呼吸频率的计算不会被打断，但正常测试情况下，基于高斯金字塔的颜色空间信号放大算法对于人脸区域的检测存在较高延迟，导致实时性较差，计算结果与实际结果存在较大的时间差；
> 2. 稳定性较差。在摄像头由于多种因素发生抖动或测试人员头部发生运动的情况下，尽管计算进程不会被打断，但心率检测结果存在较大程度的波动，会导致不正常、错误或不稳定的心率检测结果；
> 3. 呼吸频率检测精度低。在测试人员明显存在急促呼吸的情况下，计算得到的呼吸频率不会发生明显变化，即呼吸频率的实时性、精确度较低；
> 4. 同静态测试结果分析，在车辆停止状态下，心率计算结果比较稳定；在车辆运动过程中计算结果往往存在大幅变化。
> 5. 整体来看，无论是基于RGB摄像头还是红外摄像头，算法本身存在诸多关键问题，检测准确度不高，常常出现不符合正常情况的计算结果。

---------------------------------

### 解决方案3：基于Dlib人脸跟踪的rPPG检测算法（自研）

#### 1、皮肤反射模型

同解决方案1

> [!IMPORTANT]
>
> **为什么选择RGB中的绿色通道进行检测呢？**
>
> 在实际研究和应用中，绿光的波长较长，作为光源得到的信号更好，信噪比（原始信号与噪声）也比其他光源信号好一些。在rPPG相关研究中，RGB三通道里包含的信号和心率信号的关联度不一样，其中绿色通道包含了最强的心率信号。即绿色光波长对皮肤表面血管变化的敏感度较高，因此在提取rPPG信号时，绿色通道能够提供更加清晰更加准确的血管变化信息。

#### 2、方案实施过程

```python
#心率计算
def compute_ppg_signal(roi):
    """计算绿色通道的平均值，提取PPG信号."""
    _, g, _ = cv2.split(roi)  # 提取绿色通道
    g_mean = np.mean(g)  
    return g_mean

def calculate_heart_rate(signal_tensor, fps):
    """通过FFT分析信号频率来估计心率."""
    if len(signal_tensor) < fps:  
        return None

    fft_result = torch.fft.fft(signal_tensor)
    fft_magnitude = torch.abs(fft_result)
    freqs = torch.fft.fftfreq(len(signal_tensor), d=1.0 / fps)
    peaks, _ = find_peaks(fft_magnitude)
    if len(peaks) == 0:
        return None

    peak_freqs = freqs[peaks]
    valid_peak_freqs = peak_freqs[(peak_freqs > 0.8) & (peak_freqs < 3.0)]

    if len(valid_peak_freqs) == 0:
        return None  # 如果没有有效的频率峰值，返回None

    heart_rate_freq = valid_peak_freqs[
        torch.argmax(fft_magnitude[peaks[(peak_freqs > 0.8) & (peak_freqs < 3.0)]])].item()
    heart_rate_bpm = heart_rate_freq * 60
    return heart_rate_bpm

#呼吸频率计算
def calculate_respiration_rate(signal_tensor, fps):
    """通过FFT分析信号频率来估计呼吸频率."""
    if len(signal_tensor) < fps:  
        return None

    fft_result = torch.fft.fft(signal_tensor)
    fft_magnitude = torch.abs(fft_result)
    freqs = torch.fft.fftfreq(len(signal_tensor), d=1.0 / fps)
    peaks, _ = find_peaks(fft_magnitude)
    if len(peaks) == 0:
        return None

    peak_freqs = freqs[peaks]
    valid_peak_freqs = peak_freqs[(peak_freqs > 0.1) & (peak_freqs < 0.5)]

    if len(valid_peak_freqs) == 0:
        return None  # 如果没有有效的频率峰值，返回None

    respiration_rate_freq = valid_peak_freqs[
        torch.argmax(fft_magnitude[peaks[(peak_freqs > 0.1) & (peak_freqs < 0.5)]])].item()
    respiration_rate_bpm = respiration_rate_freq * 60
    return respiration_rate_bpm
```

1. **视频捕获**: 使用OpenCV从摄像头捕获视频帧。
2. **人脸检测和ROI提取**: 使用深度学习模型（Dlib）进行人脸检测，从面部提取ROI（Region of Interest），并从中提取PPG信号。这里选择前额区域（或脸颊）作为ROI，因为它们通常较少被头发遮挡，且皮肤较均匀。
3. **PPG信号提取**: 使用图像处理和信号处理技术从ROI中提取PPG信号。连续捕获视频帧，并从中提取PPG信号。这里使用一个循环来实现这个过程，计算心率和呼吸频率。计算绿色通道的平均值作为PPG信号。
4. **信号处理和频率分析**: 使用PyTorch对提取的信号进行频率分析，以估计心率和呼吸频率。

> [!NOTE]
>
> 通过FFT分析信号频率来估计心率和呼吸频率：
>
> **傅里叶变换**是一种将信号从时间域（即信号随时间变化的描述）转换到频率域（即信号的频率成分的描述）的方法。**快速傅里叶变换（FFT）** 是傅里叶变换的一种高效计算算法，用于快速计算离散傅里叶变换（DFT）。
>
> **时间域**：在时间域中，信号表示为随时间变化的幅度，例如，PPG信号或呼吸信号是随时间变化的光强度或气流的测量值。
> **频率域**：在频率域中，信号表示为不同频率分量的组合及其对应的幅度。FFT将时间域信号转换为频率域，显示信号中有哪些频率成分以及每个频率的强度。
>
> **心率**和**呼吸频率**分别对应于心跳和呼吸的周期性变化，这些变化反映在PPG信号和呼吸信号的波形中。详细的检测步骤为：
>
> | 步骤                  | 计算                                                         |
> | --------------------- | ------------------------------------------------------------ |
> | 1、采集信号           | 经过RGB摄像头获取rPPG信号，将信号采样并记录为一系列随时间变化的数据点； |
> | 2、预处理信号         | · **去噪**：基于高通或低通滤波器等在FFT之前进行去噪处理；<br />· **平滑**：移动平均滤波器或其他平滑技术减少信号的随机波动； |
> | 3、应用FFT            | 将预处理的时间域信号转化为频率阈信号；<br />计算信号的DFT，得到各频率成分的复数幅度； |
> | 4、计算幅度谱         | 对FFT结果取绝对值，得到表示信号各频率成分强度的**幅度谱；**<br />幅度谱横轴表示频率（0到采样率的一半），纵轴表示频率成分的幅度； |
> | 5、检测峰值           | 在幅度谱中寻找在心率和呼吸频率范围内的主峰（主频率成分），检查其强度确定心率和呼吸频率； |
> | 6、心率和呼吸频率计算 | · **心率**：找到在0.8 Hz到3.0 Hz范围内的主峰频率（主要代表心跳），并将该频率转换为每分钟心跳数（bpm）；<br />· **呼吸频率：**找到在0.1 Hz到0.5 Hz范围内的主峰频率（主要代表呼吸），并将该频率转换为每分钟呼吸次数。 |

#### 3、静态效果

##### 1）PC RGB Camera（30FPS）

<img src="C:\Users\kq198\Desktop\assets\image-20240828151916738.png" alt="image-20240828151916738" style="zoom:67%;" />

##### 2）PC RGB Camera（60FPS）

<img src="C:\Users\kq198\Desktop\assets\image-20240828111052733.png" alt="image-20240828111052733" style="zoom:67%;" />

##### 2）External RGB Camera（30FPS）

由于基于PC自带摄像头的算法优化暂未完成，因此暂未进行外接摄像头实验。

##### 3）External Infrared Camera（30FPS）

由于基于PC自带摄像头的算法优化暂未完成，因此暂未进行外接摄像头实验。

##### 4）静态结果分析

> [!WARNING]
>
> 1. 脸部跟踪的设定减少了头部移动对检测结果造成的影响，但算法目前并不稳定，由于经过FFT未能检测到幅度谱峰值，呼吸频率的计算经常丢失，算法关于呼吸频率的计算逻辑并不理想。
> 2. 对于外置摄像头暂时还没有写自适应图像处理程序。



-------------------------------------------------------

### 解决方案4：在线检测

> [!NOTE]
>
> **在线检测demo**：[在线demo](https://openxlab.org.cn/apps/detail/nurse1/rppg_heartrate_estimate)

#### 1、实验结果

<img src="C:\Users\kq198\Desktop\assets\image-20240829090430984.png" alt="image-20240829090430984" style="zoom:67%;" />

<img src="C:\Users\kq198\Desktop\assets\image-20240829090502990.png" alt="image-20240829090502990" style="zoom:67%;" />

#### 2、结果分析

算法限制较多，只有在测试人员保持静止或轻微移动的情况下才能实现心率检测，且心率检测计算时间较长。

### 思考

1、如何减少帧率限制给特征捕捉带来的影响？

​	1）多线程计算、高性能计算
​	2）GPU加速opencv（Linux）
​	3）提高硬件水平（cpu for windows, external camera, cpu and gpu for linux etc）
​	4）算法改进（FFT Dilb）

2、如何削弱光线变化给脸部特征捕捉带来的影响？

​	1）使用红外摄像机、捕捉影响较小波长的反射光线
​	2）补光（可见光、红外光）
​	参考：[基于视频分析的rPPG心率检测综述](https://zhuanlan.zhihu.com/p/83674059)

3、如何削弱乘客头部移动、车辆自身运动（抖动）为脸部特征捕捉带来的影响？

​	1）更改算法逻辑：
​		当捕捉到脸部超过30或40个特征点即进行计算；
​		当捕捉到脸部大于等于1部分区域的 特征点即进行计算；
​	2）增加特征捕捉设备（Camera）数量
​	3）乘客保持特征捕捉设备的相对静止

**【待补充】**
